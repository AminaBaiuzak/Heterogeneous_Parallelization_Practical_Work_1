# Практическая работа №1
Контрольные вопросы - ответы

**1. Основные отличия между массивами и динамическими структурами данных**

Массивы имеют фиксированный размер, который задаётся при компиляции или объявлении. Динамические структуры (например, динамический массив, список) позволяют изменять размер во время выполнения программы. Динамические структуры используют указатели и выделение памяти в куче (heap), тогда как статические массивы — в стеке (stack).

**2. Что такое указатель и как он используется в C++**

Указатель - это переменная, хранящая адрес другой переменной или блока памяти.
Используется для:
- работы с динамической памятью (new / delete),
- передачи больших массивов в функции без копирования,
- реализации сложных структур данных (списки, деревья).

**3. Принцип работы стека и очереди**
- Стек (stack): LIFO - Last In, First Out. Последний добавленный элемент извлекается первым.
- Очередь (queue): FIFO - First In, First Out. Первый добавленный элемент извлекается первым.

Применяются для организации данных в алгоритмах и функциях вызова.

**4. Преимущества и недостатки односвязных списков по сравнению с массивами**

Преимущества:
- Динамический размер - легко добавлять/удалять элементы.
- Эффективное использование памяти при неизвестном размере данных.

Недостатки:
- Медленный доступ к элементам по индексу (нужен перебор с головы списка).
- Больше расход памяти на хранение указателей.

**5. Как правильно освобождать память в C++ после работы с динамическими структурами**
- Для массива: delete[] ptr;
- Для одного объекта: delete ptr;
- Для списков: итерируем по элементам и освобождаем каждый узел через delete.

**6. Почему важно понимать работу с указателями и динамической памятью для параллельного программирования**

Параллельные потоки могут обращаться к одним и тем же участкам памяти. Некорректное управление указателями ведёт к гонкам данных (data races) и утечкам памяти. Для эффективного параллелизма нужно точно знать, кто и какие данные изменяет.

**7. Как использовать reduction в OpenMP**

`reduction` позволяет объединять результаты вычислений из нескольких потоков в одну переменную.

Примеры:

``` C++
#pragma omp parallel for reduction(+:sum)
for (int i = 0; i < n; i++)
    sum += arr[i];

#pragma omp parallel for reduction(min:min_val)
for (int i = 0; i < n; i++)
    if(arr[i] < min_val) min_val = arr[i];

#pragma omp parallel for reduction(max:max_val)
for (int i = 0; i < n; i++)
    if(arr[i] > max_val) max_val = arr[i];
```
Гарантирует корректность вычислений и отсутствие гонок данных.

**8. Как влияет параллельное программирование на производительность при работе с большими массивами**

Плюсы:
- Ускоряет обработку больших объёмов данных за счёт распараллеливания.
- Эффективно использует многопроцессорные системы.

Минусы:
- Для малых массивов накладные расходы на управление потоками могут превышать выигрыш.
- Возможны гонки данных и проблемы синхронизации при неправильном кодировании.
